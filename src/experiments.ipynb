{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional,LSTM,Embedding,StringLookup,Dense\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.math import reduce_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../data/kaggle-insults/raw.pickle')\n",
    "df = pd.DataFrame.from_dict({'info':data['info'],'texts':data['texts']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 00:07:55.985687: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def custom_preprocess(row):\n",
    "    return [t.text.lower() for t in nlp(row)]\n",
    "\n",
    "\n",
    "df['cleaned'] = df['texts'].apply(lambda row: custom_preprocess(row))\n",
    "cleaned_texts = tf.ragged.constant(df.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {word : word vectors}\n",
    "embeddings_index = {}\n",
    "\n",
    "for key,vector in list(nlp.vocab.vectors.items()):\n",
    "    \n",
    "    embeddings_index[nlp.vocab.strings[key]] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_layer = StringLookup()\n",
    "lookup_layer.adapt(cleaned_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = lookup_layer.get_vocabulary()\n",
    "emb_dim = 300\n",
    "\n",
    "embedding_matrix = np.zeros((len(voc),emb_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNK]\n",
      "\\\\\n",
      "custom_number\n",
      "custom_break\n",
      "pooface\n",
      "120 5\n"
     ]
    }
   ],
   "source": [
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "for i,word in enumerate(voc):\n",
    "    temp_vec = embeddings_index.get(word)\n",
    "    if temp_vec is not None:\n",
    "        embedding_matrix[i] = temp_vec\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        print(word)\n",
    "        \n",
    "print(hits,misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=len(voc),output_dim=emb_dim,embeddings_initializer=Constant(tf.constant(embedding_matrix,dtype=tf.float32)),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 300), dtype=float32, numpy=\n",
       "array([[-0.11076 ,  0.30786 , -0.5198  , ..., -0.059105,  0.47604 ,\n",
       "         0.05661 ],\n",
       "       [-0.19859 , -0.062818, -0.36614 , ..., -0.58451 ,  0.27879 ,\n",
       "        -0.26205 ],\n",
       "       [ 0.27204 , -0.06203 , -0.1884  , ...,  0.13015 , -0.18317 ,\n",
       "         0.1323  ],\n",
       "       ...,\n",
       "       [ 0.12274 , -0.29241 ,  0.32318 , ..., -0.81275 ,  0.28465 ,\n",
       "        -0.053287],\n",
       "       [ 0.012001,  0.20751 , -0.12578 , ...,  0.13871 , -0.36049 ,\n",
       "        -0.035   ],\n",
       "       [-0.49594 ,  0.26918 , -0.18897 , ...,  0.027965,  0.029533,\n",
       "         0.031204]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(lookup_layer(cleaned_texts[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepmojiNet(Model):\n",
    "    def __init__(self,lookup_layer,embedding_layer,out_dim):\n",
    "        super().__init__()\n",
    "        self.lookup_layer = lookup_layer\n",
    "        self.embedding_layer = embedding_layer\n",
    "        self.lstm1 = Bidirectional(LSTM(units=512,return_sequences=True))\n",
    "        self.lstm2 = Bidirectional(LSTM(units=512,return_sequences=True))\n",
    "        self.dense1 = Dense(units=1, activation='relu')\n",
    "        self.dense2 = Dense(units=128, activation='relu')\n",
    "        self.dense3 = Dense(units=out_dim, activation=None)\n",
    "\n",
    "    def call(self,x):\n",
    "        idx = self.lookup_layer(x)\n",
    "        embs = self.embedding_layer(idx)\n",
    "        # put F.tanh here?\n",
    "\n",
    "        hiddens1 = self.lstm1(embs)\n",
    "        hiddens2 = self.lstm2(hiddens1)\n",
    "\n",
    "        word_repr = tf.concat([embs,hiddens1,hiddens2],axis=-1)\n",
    "        o = self.dense1(word_repr)\n",
    "        att_weights = softmax(o,axis=1)\n",
    "        sent_repr = reduce_sum(word_repr * att_weights,axis=1)\n",
    "\n",
    "        output = self.dense2(sent_repr)\n",
    "        output = self.dense3(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepmojiNet(lookup_layer,embedding_layer,2)\n",
    "temp_x = cleaned_texts[3]\n",
    "temp_x = tf.expand_dims(temp_x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(temp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6437ff6c85c757ceba5db2a6998c4f1669d0f62cfc0e179dab4e1fccc2692370"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
